    # Epoch 1/250
    # 1600/1600 [==============================] - 4970s 3s/step - loss: 36.166 - val_loss: 6.7241
    # Epoch 5/250
    # 1600/1600 [==============================] - 4952s 3s/step - loss: 6.2326 - val_loss: 5.1956
    # Epoch 6/250
    # 1600/1600 [==============================] - 4906s 3s/step - loss: 5.3712 - val_loss: 4.7031
    # Epoch 4/250
    # 1600/1600 [==============================] - 4970s 3s/step - loss: 5.0922 - val_loss: 4.4992
    # Epoch 5/250
    # 1600/1600 [==============================] - 4952s 3s/step - loss: 4.5979 - val_loss: 3.9611
    # Epoch 6/250
    # 1600/1600 [==============================] - 4906s 3s/step - loss: 4.3305 - val_loss: 3.8423
    # Epoch 7/250
    # 1600/1600 [==============================] - 4973s 3s/step - loss: 4.1514 - val_loss: 3.4939
    # Epoch 8/250
    # 1600/1600 [==============================] - 4943s 3s/step - loss: 3.9295 - val_loss: 3.2480
    # Epoch 9/250
    # 1600/1600 [==============================] - 4867s 3s/step - loss: 3.8196 - val_loss: 3.2813
    # Epoch 10/250
    # 1600/1600 [==============================] - 4880s 3s/step - loss: 3.7062 - val_loss: 3.2720
    # Epoch 11/250
    # 1600/1600 [==============================] - 4869s 3s/step - loss: 3.5978 - val_loss: 3.2084
    # Epoch 12/250
    # 1600/1600 [==============================] - 4884s 3s/step - loss: 3.5349 - val_loss: 3.2265
    # Epoch 13/250
    # 1600/1600 [==============================] - 4895s 3s/step - loss: 3.4705 - val_loss: 2.9859
    # Epoch 14/250
    # 1600/1600 [==============================] - 4891s 3s/step - loss: 3.3872 - val_loss: 3.0937
    # Epoch 15/250
    # 1600/1600 [==============================] - 4866s 3s/step - loss: 3.3051 - val_loss: 2.9948
    # Epoch 16/250
    # 1600/1600 [==============================] - 4861s 3s/step - loss: 3.2831 - val_loss: 2.9360
    # Epoch 17/250
    # 1600/1600 [==============================] - 4868s 3s/step - loss: 3.1858 - val_loss: 3.0259
    # Epoch 18/250
    # 1600/1600 [==============================] - 4952s 3s/step - loss: 3.1701 - val_loss: 2.9079
    # Epoch 19/250
    # 1600/1600 [==============================] - 4963s 3s/step - loss: 3.0896 - val_loss: 2.8858
    # Epoch 20/250
    # 1600/1600 [==============================] - 4903s 3s/step - loss: 3.1119 - val_loss: 2.7995
    # Epoch 21/250
    # 1600/1600 [==============================] - 5116s 3s/step - loss: 3.0445 - val_loss: 2.7876
    # Epoch 22/250
    # 1600/1600 [==============================] - 5237s 3s/step - loss: 2.9627 - val_loss: 2.8871
    # Epoch 23/250
    # 1600/1600 [==============================] - 4938s 3s/step - loss: 2.9607 - val_loss: 2.7918
    # Epoch 24/250
    # 1600/1600 [==============================] - ETA: 0s - loss: 2.9712
    # Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
    # 1600/1600 [==============================] - 4946s 3s/step - loss: 2.9712 - val_loss: 2.8582
    # Epoch 25/250
    # 1600/1600 [==============================] - 4973s 3s/step - loss: 2.6839 - val_loss: 2.4534
    # Epoch 26/250
    # 1600/1600 [==============================] - 5301s 3s/step - loss: 2.5865 - val_loss: 2.5393
    # Epoch 27/250
    # 1600/1600 [==============================] - 4844s 3s/step - loss: 2.5873 - val_loss: 2.4939
    # Epoch 28/250
    # 1600/1600 [==============================] - 4853s 3s/step - loss: 2.5283 - val_loss: 2.4220
    # Epoch 29/250
    # 1600/1600 [==============================] - 4852s 3s/step - loss: 2.5004 - val_loss: 2.3658
    # Epoch 30/250
    # 1600/1600 [==============================] - 4855s 3s/step - loss: 2.5108 - val_loss: 2.4580
    # Epoch 31/250
    # 1600/1600 [==============================] - 4849s 3s/step - loss: 2.4780 - val_loss: 2.3377
    # Epoch 32/250
    # 1600/1600 [==============================] - 4851s 3s/step - loss: 2.4481 - val_loss: 2.3765
    # Epoch 33/250
    # 1600/1600 [==============================] - 4856s 3s/step - loss: 2.4441 - val_loss: 2.4612
    # Epoch 34/250
    # 1600/1600 [==============================] - ETA: 0s - loss: 2.4383
    # Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
    # 1600/1600 [==============================] - 4844s 3s/step - loss: 2.4383 - val_loss: 2.3839
    # Epoch 35/250
    # 1600/1600 [==============================] - 4848s 3s/step - loss: 2.3406 - val_loss: 2.3051
    # Epoch 36/250
    # 1600/1600 [==============================] - 4843s 3s/step - loss: 2.2477 - val_loss: 2.2659
    # Epoch 37/250
    # 1600/1600 [==============================] - 4840s 3s/step - loss: 2.2216 - val_loss: 2.3333
    # Epoch 38/250
    # 1600/1600 [==============================] - 4843s 3s/step - loss: 2.2568 - val_loss: 2.3369
